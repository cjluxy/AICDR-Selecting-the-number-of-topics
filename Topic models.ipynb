{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "027e06f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re,time\n",
    "import  matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "# plt.rcParams['font.sans-serif']=['SimHei']\n",
    "# plt.rcParams['axes.unicode_minus'] = False\n",
    "from numpy.linalg import norm    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb3dce65-56e8-4526-9b44-6740deebdbd9",
   "metadata": {},
   "source": [
    "# data_process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0746699c-c6fb-4af4-88d6-ef7c09386b2d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the number of docs7409,the number of word4607\n",
      "tf-idf (7409, 4607)\n"
     ]
    }
   ],
   "source": [
    "path=r'.\\input\\ag_news\\ag_news_gsdmm.xlsx'\n",
    "data_initial=pd.read_excel(path)\n",
    "\n",
    "\n",
    "vocab_max_size=10000   \n",
    "vocab_min_count=5\n",
    "data=data_initial['new_nltk'].values.tolist()\n",
    "data_matrix=[text.split()  for text in data]\n",
    "data=[ele for row in data_matrix for ele in row]\n",
    "\n",
    "vocab =Counter(data)\n",
    "vocab_arr = [[wd, vocab[wd]] for wd in vocab if vocab[wd] >vocab_min_count] \n",
    "vocab_arr = sorted(vocab_arr, key=lambda k: k[1])[::-1]   \n",
    "vocab_arr = sorted(vocab_arr)              \n",
    "vocab2id = {value[0]:itm for itm,value in enumerate(vocab_arr)}\n",
    "\n",
    "#text-word\n",
    "doc_word_matrix=[]\n",
    "for row in data_matrix:\n",
    "    temp_row=[]\n",
    "    for word in row:\n",
    "        if word in vocab2id:\n",
    "            temp_row.append(vocab2id[word])\n",
    "    doc_word_matrix.append(temp_row)\n",
    "\n",
    "#text-word\n",
    "doc_word_matrix1=[]\n",
    "for row in data_matrix:\n",
    "    temp_row=[]\n",
    "    for word in row:\n",
    "        if word in vocab2id:\n",
    "            temp_row.append(word)\n",
    "    doc_word_matrix1.append(temp_row)  \n",
    "    \n",
    "    \n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "docs = doc_word_matrix  \n",
    "vocab = list(vocab2id.keys())  \n",
    "n_docs = len(docs)   \n",
    "n_terms = len(vocab) \n",
    "fix_seed=np.random.seed(0)\n",
    "print(f'the number of docs{n_docs},the number of word{n_terms}')\n",
    "\n",
    "\n",
    "# only for SeaNMF\n",
    "# #PMI\n",
    "# dt_mat = np.zeros([n_terms, n_terms])\n",
    "# for itm in docs: \n",
    "#     for kk in itm:\n",
    "#         for jj in itm:\n",
    "#             if kk!=jj:\n",
    "#                 dt_mat[int(kk),int(jj)] += 1.0\n",
    "# D1 = np.sum(dt_mat)\n",
    "# SS = D1*dt_mat\n",
    "# print('SS done')\n",
    "# for k in range(n_terms):\n",
    "#     SS[k] /= np.sum(dt_mat[k])  \n",
    "# for k in range(n_terms):\n",
    "#     SS[:,k] /= np.sum(dt_mat[:,k])  \n",
    "# dt_mat = [] # release memory\n",
    "# SS[SS==0] = 1.0\n",
    "# SS = np.maximum(np.log(SS),0.0)\n",
    "# print('PPMI done',SS.shape)\n",
    "\n",
    "\n",
    "#tf-idf\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "doc_word_matrix_temp=['  '.join(doc) for doc in doc_word_matrix1]\n",
    "tv = TfidfVectorizer()  \n",
    "tv_fit = tv.fit_transform(doc_word_matrix_temp)\n",
    "tfidf_matrix=pd.DataFrame(tv_fit.toarray(),columns=tv.get_feature_names_out())\n",
    "print('tf-idf',tv_fit.toarray().shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "45ba553c-26c4-4bd1-894f-5f23c330bce1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "term doc matrix done\n"
     ]
    }
   ],
   "source": [
    "dt_mat = np.zeros([n_docs,n_terms])\n",
    "for k in range(n_docs):\n",
    "    for j in docs[k]:\n",
    "        dt_mat[k, j] = dt_mat[k, j]+1.0\n",
    "        # if k==0:\n",
    "        #     print(k,'  ',j,dt_mat[k, j])\n",
    "\n",
    "print('term doc matrix done')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2021fa7a-c5eb-429a-9de6-ac8ec2cdd35f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# kmeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a602bfc3-4e75-432a-89fa-3e5834489635",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " Topic is 2\n",
      "Counter({0: 976, 1: 423})\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      " Topic is 3\n",
      "Counter({2: 566, 1: 447, 0: 386})\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      " Topic is 4\n",
      "Counter({2: 558, 1: 399, 3: 328, 0: 114})\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      " Topic is 5\n",
      "Counter({3: 543, 0: 351, 4: 243, 2: 158, 1: 104})\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      " Topic is 6\n",
      "Counter({4: 413, 5: 392, 2: 306, 3: 155, 1: 96, 0: 37})\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      " Topic is 7\n",
      "Counter({0: 454, 2: 284, 5: 205, 6: 166, 1: 156, 3: 97, 4: 37})\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      " Topic is 8\n",
      "Counter({0: 398, 7: 249, 4: 244, 2: 144, 3: 114, 1: 109, 5: 104, 6: 37})\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      " Topic is 9\n",
      "Counter({7: 374, 0: 253, 6: 247, 1: 169, 2: 132, 4: 85, 5: 59, 8: 43, 3: 37})\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      " Topic is 10\n",
      "Counter({2: 334, 3: 278, 1: 226, 4: 145, 8: 112, 7: 99, 9: 80, 0: 55, 5: 37, 6: 33})\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      " Topic is 11\n",
      "Counter({3: 291, 10: 245, 4: 202, 1: 146, 7: 118, 9: 99, 0: 78, 8: 73, 2: 56, 6: 54, 5: 37})\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      " Topic is 12\n",
      "Counter({1: 329, 3: 198, 2: 134, 5: 130, 11: 127, 6: 94, 9: 91, 7: 86, 8: 77, 10: 53, 0: 43, 4: 37})\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      " Topic is 13\n",
      "Counter({7: 233, 9: 208, 10: 132, 0: 120, 12: 119, 5: 113, 1: 102, 11: 79, 3: 78, 4: 77, 2: 72, 8: 37, 6: 29})\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      " Topic is 14\n",
      "Counter({5: 228, 10: 192, 1: 183, 4: 129, 7: 100, 8: 99, 0: 92, 6: 82, 2: 71, 9: 62, 12: 54, 13: 42, 3: 37, 11: 28})\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      " Topic is 15\n",
      "Counter({9: 236, 2: 171, 8: 121, 12: 118, 10: 112, 1: 90, 3: 87, 0: 86, 14: 84, 4: 73, 7: 54, 11: 49, 6: 45, 5: 37, 13: 36})\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      " Topic is 16\n",
      "Counter({8: 211, 0: 186, 7: 151, 1: 120, 3: 88, 15: 82, 11: 79, 6: 78, 10: 76, 4: 72, 14: 57, 9: 52, 13: 42, 2: 41, 5: 37, 12: 27})\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      " Topic is 17\n",
      "Counter({2: 294, 1: 181, 3: 149, 6: 110, 10: 101, 16: 91, 4: 82, 5: 74, 8: 62, 14: 48, 7: 45, 15: 42, 13: 37, 12: 33, 11: 29, 0: 12, 9: 9})\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      " Topic is 18\n",
      "Counter({15: 208, 8: 154, 9: 121, 6: 111, 5: 105, 3: 95, 16: 79, 10: 75, 4: 62, 0: 61, 1: 59, 11: 51, 14: 48, 2: 43, 13: 42, 17: 37, 7: 27, 12: 21})\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      " Topic is 19\n",
      "Counter({3: 213, 12: 144, 14: 105, 6: 97, 9: 94, 5: 84, 8: 79, 2: 75, 4: 63, 18: 61, 10: 56, 16: 53, 7: 52, 11: 49, 17: 45, 0: 37, 13: 33, 1: 30, 15: 29})\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      " Topic is 20\n",
      "Counter({11: 229, 12: 152, 5: 121, 6: 106, 2: 82, 4: 80, 14: 76, 13: 72, 7: 71, 3: 63, 15: 47, 16: 46, 8: 41, 19: 39, 10: 37, 1: 34, 17: 32, 9: 31, 18: 26, 0: 14})\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "for j in range(2,21):\n",
    "    kmeans = KMeans(n_clusters=j, random_state=42).fit(tv_fit.toarray())\n",
    "    kmeans_pred=kmeans.labels_\n",
    "    print('\\n\\n',f'Topic is {j}') \n",
    "    print(Counter(kmeans_pred))\n",
    "    name='topic'+str(j)\n",
    "    data_initial.insert(j+1, name, kmeans_pred.astype(int))\n",
    "    print('--'*50)\n",
    "data_initial.to_excel(path,index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e11f6e8-a678-4611-a297-1de62eab146b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# NMF„ÄÅSeaNMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "68b5f699-3b7f-4da7-8447-5dbabc3cd1bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Short Text Topic Modeling via SeaNMF\n",
    "'''\n",
    "\n",
    "\n",
    "class SeaNMF(object):\n",
    "    def __init__(\n",
    "        self,\n",
    "        A, S,    \n",
    "        IW1=[], IW2=[], IH=[],\n",
    "        alpha=1.0, beta=0.1, n_topic=10, max_iter=100, max_err=1e-3, \n",
    "        rand_init=True, fix_seed=False):\n",
    "        \n",
    "        '''\n",
    "        0.5*||A-WH^T||_F^2+0.5*alpha*||S-WW_c^T||_F^2+0.5*beta*||W||_1^2\n",
    "        W = W1\n",
    "        Wc = W2\n",
    "        '''\n",
    "        if fix_seed: \n",
    "            np.random.seed(0)\n",
    "            \n",
    "        self.obj=[] \n",
    "        \n",
    "        self.A = A   \n",
    "        self.S = S   \n",
    "        self.n_row = A.shape[0]\n",
    "        self.n_col = A.shape[1]\n",
    "        self.n_topic = n_topic\n",
    "        self.max_iter = max_iter\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "        self.B = np.ones([self.n_topic,1]) \n",
    "        self.max_err = max_err \n",
    "\n",
    "        if rand_init:\n",
    "            self.nmf_init_rand()\n",
    "        else:\n",
    "            self.nmf_init(IW1, IW2, IH)\n",
    "        self.nmf_iter()\n",
    "\n",
    "    def nmf_init_rand(self):\n",
    "        self.W1 = np.random.random((self.n_row, self.n_topic))\n",
    "        self.W2 = np.random.random((self.n_row, self.n_topic))\n",
    "        self.H = np.random.random((self.n_col, self.n_topic))\n",
    "        print(self.W1.shape,self.W2.shape,self.H.shape,self.A.shape)\n",
    "\n",
    "        for k in range(self.n_topic):\n",
    "            self.W1[:, k] /= norm(self.W1[:, k])    # np.linalg.norm\n",
    "            self.W2[:, k] /= norm(self.W2[:, k])\n",
    "\n",
    "    def nmf_init(self, IW1, IW2, IH):\n",
    "        self.W1 = IW1\n",
    "        self.W2 = IW2\n",
    "        self.H = IH\n",
    "\n",
    "        for k in range(self.n_topic):\n",
    "            self.W1[:, k] /= norm(self.W1[:, k])\n",
    "            self.W2[:, k] /= norm(self.W2[:, k])\n",
    "\n",
    "\n",
    "    def nmf_iter(self):\n",
    "        loss_old = 1e20\n",
    "        print('loop begin')\n",
    "        start_time = time.time()\n",
    "        for i in range(self.max_iter):\n",
    "            self.nmf_solver() \n",
    "            loss = self.nmf_loss()  \n",
    "#             print(i,' ',loss)\n",
    "            self.obj.append(loss)\n",
    "            if loss_old-loss < self.max_err:  #  0.001\n",
    "                break\n",
    "            loss_old = loss\n",
    "            end_time = time.time()\n",
    "            print('Step={}, Loss={}, Time={}s'.format(i, loss, end_time-start_time))\n",
    "            \n",
    "    def nmf_solver(self):\n",
    "        '''\n",
    "        using BCD framework\n",
    "        '''\n",
    "        epss = 1e-20\n",
    "        # Update W1\n",
    "        AH = np.dot(self.A, self.H)  \n",
    "        SW2 = np.dot(self.S, self.W2)  \n",
    "        HtH = np.dot(self.H.T, self.H) \n",
    "        W2tW2 = np.dot(self.W2.T, self.W2)\n",
    "        W11 = self.W1.dot(self.B)\n",
    "#         print(sum(AH),sum(SW2),sum(HtH),sum(W2tW2),sum(W11))\n",
    "        for k in range(self.n_topic):\n",
    "            num0 = HtH[k,k]*self.W1[:,k] + self.alpha*W2tW2[k,k]*self.W1[:,k]\n",
    "            num1 = AH[:,k] + self.alpha*SW2[:,k]\n",
    "            num2 = np.dot(self.W1, HtH[:,k]) + self.alpha*np.dot(self.W1, W2tW2[:,k]) + self.beta*W11[0]\n",
    "#             print('---------',num2.shape,W11.shape,W11[0].shape)\n",
    "            self.W1[:,k] = num0 + num1 - num2\n",
    "            self.W1[:,k] = np.maximum(self.W1[:,k], epss) # project > 0\n",
    "            self.W1[:,k] /= norm(self.W1[:,k]) + epss # normalize\n",
    "            \n",
    "            \n",
    "        # Update W2\n",
    "        W1tW1 = self.W1.T.dot(self.W1)\n",
    "        StW1 = np.dot(self.S, self.W1)\n",
    "        for k in range(self.n_topic):\n",
    "            self.W2[:,k] = self.W2[:,k] + StW1[:,k] - np.dot(self.W2, W1tW1[:,k])\n",
    "            self.W2[:,k] = np.maximum(self.W2[:,k], epss)\n",
    "        #Update H\n",
    "        AtW1 = np.dot(self.A.T, self.W1)\n",
    "        for k in range(self.n_topic):\n",
    "            self.H[:,k] = self.H[:,k] + AtW1[:,k] - np.dot(self.H, W1tW1[:,k])\n",
    "            self.H[:,k] = np.maximum(self.H[:,k], epss) \n",
    "            \n",
    "            \n",
    "\n",
    "    def nmf_loss(self):\n",
    "        '''\n",
    "        Calculate loss\n",
    "        '''\n",
    "        loss = norm(self.A - np.dot(self.W1, np.transpose(self.H)), 'fro')**2/2.0\n",
    "        if self.alpha > 0:\n",
    "            loss += self.alpha*norm(np.dot(self.W1, np.transpose(self.W2))-self.S, 'fro')**2/2.0\n",
    "        if self.beta > 0:\n",
    "            loss += self.beta*norm(self.W1, 1)**2/2.0\n",
    "            \n",
    "        return loss\n",
    "    def return_loss(self):\n",
    "        return self.obj\n",
    "    \n",
    "    def return_weight(self):\n",
    "        return self.W1, self.W2, self.H\n",
    "    \n",
    "        \n",
    "        \n",
    "        \n",
    "'''\n",
    "Topic Modeling via NMF\n",
    "'''\n",
    "class NMF(object):   \n",
    "    def __init__(\n",
    "        self, \n",
    "        A, n_topic,IW=[], IH=[],\n",
    "         max_iter=100, max_err=1e-3,\n",
    "        rand_init=True):\n",
    "        '''\n",
    "        A = WH^T\n",
    "        '''\n",
    "        self.A = A   #  input\n",
    "        self.n_row = A.shape[0]\n",
    "        self.n_col = A.shape[1]\n",
    "        self.n_topic = n_topic\n",
    "        self.max_iter = max_iter\n",
    "        self.max_err = max_err\n",
    "\n",
    "        self.obj = []\n",
    "        if rand_init:\n",
    "            self.nmf_init_rand()\n",
    "        else:\n",
    "            self.nmf_init(IW, IH)\n",
    "        self.nmf_iter()\n",
    "\n",
    "    def nmf_init_rand(self):\n",
    "        self.W = np.random.random((self.n_row, self.n_topic))\n",
    "        self.H = np.random.random((self.n_col, self.n_topic))\n",
    "\n",
    "        print('nmf_init_rand')\n",
    "        for k in range(self.n_topic):\n",
    "            self.W[:,k] /= norm(self.W[:,k])\n",
    "        print(self.W.shape,self.H.shape)\n",
    "\n",
    "    def nmf_init(self, IW, IH):\n",
    "        self.W = IW\n",
    "        self.H = IH\n",
    "        print('nmf_init')\n",
    "        # for k in range(self.n_topic):\n",
    "        #     self.W[:,k] /= norm(self.W[:,k])\n",
    "    def nmf_iter(self):\n",
    "        loss_old = 1e20\n",
    "        start_time = time.time()         \n",
    "        for i in range(self.max_iter):\n",
    "            self.nmf_solver()    \n",
    "            loss = self.nmf_loss()   \n",
    "            self.obj.append(loss)\n",
    "            if loss_old-loss < self.max_err:\n",
    "                break\n",
    "            loss_old = loss\n",
    "            end_time = time.time()\n",
    "            print('iter:{}, loss:{}, time{}s'.format(i, round(loss,5), end_time-start_time))            \n",
    "    def nmf_solver(self):\n",
    "        '''\n",
    "        regular NMF without constraint.\n",
    "        Block Coordinate Decent\n",
    "        '''\n",
    "        epss = 1e-20       \n",
    "      \n",
    "        HtH = self.H.T.dot(self.H) \n",
    "        AH = self.A.dot(self.H)  \n",
    "#         H:(15001, 10) A:(2443, 15001) HTH(10, 10) AH:(2443, 10) W:(2443, 10)\n",
    "#         print(f'H:{self.H.shape} A:{self.A.shape} HTH{HtH.shape} AH:{AH.shape} W:{self.W.shape}')\n",
    "        for k in range(self.n_topic):\n",
    "            tmpW = self.W[:,k]*HtH[k,k] + AH[:,k] - np.dot(self.W, HtH[:,k])\n",
    "            self.W[:,k] = np.maximum(tmpW, epss)\n",
    "            self.W[:,k] /= norm(self.W[:,k]) + epss\n",
    "        WtW = self.W.T.dot(self.W)\n",
    "        AtW = self.A.T.dot(self.W)\n",
    "        for k in range(self.n_topic):\n",
    "            self.H[:,k] = self.H[:,k]*WtW[k,k] + AtW[:,k] - np.dot(self.H, WtW[:,k])\n",
    "            self.H[:,k] = np.maximum(self.H[:,k], epss)\n",
    "    def nmf_loss(self):\n",
    "        loss = norm(self.A - np.dot(self.W, self.H.T), 'fro')**2/2.0\n",
    "        return loss \n",
    "    def get_loss(self):\n",
    "        return np.array(self.obj) \n",
    "    def return_weight(self):\n",
    "        return self.W,self.H"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e51101d0-0798-4570-87b9-7bba8c7a95d4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#  NMF long text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c29eeafe-2dae-4643-b611-d02e0f61feba",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=tv_fit.toarray().T  \n",
    "max_iter=100\n",
    "max_err=1e-3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cd6939a4-00e5-4461-aee6-820a121a3940",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nmf_init\n",
      "iter:0, loss:350.64707, time0.025780677795410156s\n",
      "iter:1, loss:349.74896, time0.062027931213378906s\n",
      "iter:2, loss:349.5364, time0.08876776695251465s\n",
      "iter:3, loss:349.44942, time0.11713027954101562s\n",
      "iter:4, loss:349.41395, time0.1458578109741211s\n",
      "iter:5, loss:349.39868, time0.1739215850830078s\n",
      "iter:6, loss:349.39171, time0.20156240463256836s\n",
      "iter:7, loss:349.38829, time0.23219013214111328s\n",
      "iter:8, loss:349.3865, time0.263073205947876s\n",
      "iter:9, loss:349.38549, time0.29103517532348633s\n",
      "iter:0, loss:349.38455, time0.03334355354309082s\n",
      "\n",
      "\n",
      " Topic is 2\n",
      "Counter({0.0: 486, 1.0: 251})\n",
      "----------------------------------------------------------------------------------------------------\n",
      "nmf_init\n",
      "iter:0, loss:345.78235, time0.03145432472229004s\n",
      "iter:1, loss:344.7011, time0.05091047286987305s\n",
      "iter:2, loss:344.37817, time0.0874643325805664s\n",
      "iter:3, loss:344.23952, time0.11754894256591797s\n",
      "iter:4, loss:344.1785, time0.14668560028076172s\n",
      "iter:5, loss:344.14826, time0.16773319244384766s\n",
      "iter:6, loss:344.13144, time0.20142197608947754s\n",
      "iter:7, loss:344.12092, time0.23596644401550293s\n",
      "iter:8, loss:344.1138, time0.2673666477203369s\n",
      "iter:9, loss:344.10873, time0.29694437980651855s\n",
      "iter:10, loss:344.10508, time0.32486939430236816s\n",
      "iter:11, loss:344.10246, time0.3528742790222168s\n",
      "iter:12, loss:344.10059, time0.381847620010376s\n",
      "iter:13, loss:344.09928, time0.41706037521362305s\n",
      "iter:0, loss:344.09776, time0.033350229263305664s\n",
      "\n",
      "\n",
      " Topic is 3\n",
      "Counter({0.0: 279, 1.0: 253, 2.0: 205})\n",
      "----------------------------------------------------------------------------------------------------\n",
      "nmf_init\n",
      "iter:0, loss:341.40495, time0.01549220085144043s\n",
      "iter:1, loss:340.01241, time0.0558929443359375s\n",
      "iter:2, loss:339.61833, time0.07349300384521484s\n",
      "iter:3, loss:339.4126, time0.10985708236694336s\n",
      "iter:4, loss:339.30109, time0.12524867057800293s\n",
      "iter:5, loss:339.23507, time0.16570377349853516s\n",
      "iter:6, loss:339.19398, time0.1844336986541748s\n",
      "iter:7, loss:339.16753, time0.2367401123046875s\n",
      "iter:8, loss:339.14996, time0.26859354972839355s\n",
      "iter:9, loss:339.13816, time0.292604923248291s\n",
      "iter:10, loss:339.13046, time0.3400084972381592s\n",
      "iter:11, loss:339.12561, time0.3788182735443115s\n",
      "iter:12, loss:339.12257, time0.4062340259552002s\n",
      "iter:13, loss:339.12067, time0.4218928813934326s\n",
      "iter:14, loss:339.11948, time0.467787504196167s\n",
      "iter:0, loss:339.11827, time0.02710127830505371s\n",
      "\n",
      "\n",
      " Topic is 4\n",
      "Counter({1.0: 254, 2.0: 205, 0.0: 154, 3.0: 124})\n",
      "----------------------------------------------------------------------------------------------------\n",
      "nmf_init\n",
      "iter:0, loss:338.07943, time0.015659809112548828s\n",
      "iter:1, loss:336.04579, time0.04686570167541504s\n",
      "iter:2, loss:335.51095, time0.08503580093383789s\n",
      "iter:3, loss:335.25467, time0.11194729804992676s\n",
      "iter:4, loss:335.11847, time0.12755870819091797s\n",
      "iter:5, loss:335.0396, time0.16149210929870605s\n",
      "iter:6, loss:334.99302, time0.18834805488586426s\n",
      "iter:7, loss:334.9652, time0.2281644344329834s\n",
      "iter:8, loss:334.94847, time0.25696468353271484s\n",
      "iter:9, loss:334.93821, time0.27562594413757324s\n",
      "iter:10, loss:334.93198, time0.31313538551330566s\n",
      "iter:11, loss:334.92831, time0.3408510684967041s\n",
      "iter:12, loss:334.92614, time0.36052513122558594s\n",
      "iter:13, loss:334.92485, time0.3923013210296631s\n",
      "iter:0, loss:334.92364, time0.03337979316711426s\n",
      "\n",
      "\n",
      " Topic is 5\n",
      "Counter({1.0: 253, 2.0: 170, 0.0: 154, 3.0: 125, 4.0: 35})\n",
      "----------------------------------------------------------------------------------------------------\n",
      "nmf_init\n",
      "iter:0, loss:335.93846, time0.027918577194213867s\n",
      "iter:1, loss:333.24148, time0.04962277412414551s\n",
      "iter:2, loss:332.23922, time0.08599638938903809s\n",
      "iter:3, loss:331.76206, time0.11398625373840332s\n",
      "iter:4, loss:331.53296, time0.1426100730895996s\n",
      "iter:5, loss:331.42109, time0.1582322120666504s\n",
      "iter:6, loss:331.37011, time0.19851922988891602s\n",
      "iter:7, loss:331.34904, time0.24091863632202148s\n",
      "iter:8, loss:331.34136, time0.26672887802124023s\n",
      "iter:9, loss:331.33787, time0.2991371154785156s\n",
      "iter:10, loss:331.33596, time0.32674717903137207s\n",
      "iter:11, loss:331.33483, time0.3537716865539551s\n",
      "iter:0, loss:331.33363, time0.0288846492767334s\n",
      "\n",
      "\n",
      " Topic is 6\n",
      "Counter({1.0: 253, 2.0: 167, 0.0: 156, 3.0: 79, 5.0: 44, 4.0: 38})\n",
      "----------------------------------------------------------------------------------------------------\n",
      "nmf_init\n",
      "iter:0, loss:334.17881, time0.03594851493835449s\n",
      "iter:1, loss:331.20399, time0.06846070289611816s\n",
      "iter:2, loss:329.05349, time0.08412480354309082s\n",
      "iter:3, loss:328.01707, time0.1272897720336914s\n",
      "iter:4, loss:327.67093, time0.15573763847351074s\n",
      "iter:5, loss:327.56282, time0.17694401741027832s\n",
      "iter:6, loss:327.52706, time0.21203112602233887s\n",
      "iter:7, loss:327.51462, time0.2420639991760254s\n",
      "iter:8, loss:327.50999, time0.2690439224243164s\n",
      "iter:9, loss:327.50819, time0.28787803649902344s\n",
      "iter:0, loss:327.50716, time0.04553031921386719s\n",
      "\n",
      "\n",
      " Topic is 7\n",
      "Counter({1.0: 253, 0.0: 155, 2.0: 98, 3.0: 79, 5.0: 79, 6.0: 44, 4.0: 29})\n",
      "----------------------------------------------------------------------------------------------------\n",
      "nmf_init\n",
      "iter:0, loss:332.04814, time0.028811931610107422s\n",
      "iter:1, loss:328.87317, time0.05090761184692383s\n",
      "iter:2, loss:326.62577, time0.08215093612670898s\n",
      "iter:3, loss:325.55804, time0.12369537353515625s\n",
      "iter:4, loss:325.16661, time0.14397668838500977s\n",
      "iter:5, loss:325.01176, time0.17525863647460938s\n",
      "iter:6, loss:324.9329, time0.2159101963043213s\n",
      "iter:7, loss:324.88374, time0.2478775978088379s\n",
      "iter:8, loss:324.85015, time0.26852941513061523s\n",
      "iter:9, loss:324.82707, time0.30997514724731445s\n",
      "iter:10, loss:324.81138, time0.3385334014892578s\n",
      "iter:11, loss:324.80097, time0.36722445487976074s\n",
      "iter:12, loss:324.79418, time0.3969428539276123s\n",
      "iter:13, loss:324.78981, time0.4265708923339844s\n",
      "iter:14, loss:324.78703, time0.4614250659942627s\n",
      "iter:15, loss:324.78527, time0.4906141757965088s\n",
      "iter:16, loss:324.78416, time0.5160989761352539s\n",
      "iter:0, loss:324.78304, time0.015657901763916016s\n",
      "\n",
      "\n",
      " Topic is 8\n",
      "Counter({1.0: 249, 2.0: 98, 0.0: 91, 3.0: 79, 5.0: 79, 7.0: 69, 6.0: 43, 4.0: 29})\n",
      "----------------------------------------------------------------------------------------------------\n",
      "nmf_init\n",
      "iter:0, loss:329.47368, time0.01693415641784668s\n",
      "iter:1, loss:326.10399, time0.04821181297302246s\n",
      "iter:2, loss:323.80961, time0.0886373519897461s\n",
      "iter:3, loss:322.74542, time0.1185147762298584s\n",
      "iter:4, loss:322.35754, time0.1392049789428711s\n",
      "iter:5, loss:322.20463, time0.1704423427581787s\n",
      "iter:6, loss:322.12726, time0.20737075805664062s\n",
      "iter:7, loss:322.07976, time0.23828935623168945s\n",
      "iter:8, loss:322.04808, time0.25781679153442383s\n",
      "iter:9, loss:322.0268, time0.29849886894226074s\n",
      "iter:10, loss:322.01271, time0.31487488746643066s\n",
      "iter:11, loss:322.00345, time0.3435397148132324s\n",
      "iter:12, loss:321.9975, time0.38524818420410156s\n",
      "iter:13, loss:321.99371, time0.41732072830200195s\n",
      "iter:14, loss:321.99133, time0.44962286949157715s\n",
      "iter:15, loss:321.98982, time0.47228527069091797s\n",
      "iter:0, loss:321.98831, time0.02584528923034668s\n",
      "\n",
      "\n",
      " Topic is 9\n",
      "Counter({1.0: 216, 2.0: 98, 0.0: 90, 3.0: 79, 5.0: 79, 7.0: 69, 6.0: 43, 8.0: 34, 4.0: 29})\n",
      "----------------------------------------------------------------------------------------------------\n",
      "nmf_init\n",
      "iter:0, loss:327.41609, time0.02978038787841797s\n",
      "iter:1, loss:323.9045, time0.04713606834411621s\n",
      "iter:2, loss:321.69097, time0.0895841121673584s\n",
      "iter:3, loss:320.62805, time0.11946487426757812s\n",
      "iter:4, loss:320.20948, time0.14017868041992188s\n",
      "iter:5, loss:320.02198, time0.17856454849243164s\n",
      "iter:6, loss:319.90799, time0.20195579528808594s\n",
      "iter:7, loss:319.82395, time0.2427501678466797s\n",
      "iter:8, loss:319.759, time0.28429341316223145s\n",
      "iter:9, loss:319.71189, time0.30297017097473145s\n",
      "iter:10, loss:319.68032, time0.3498380184173584s\n",
      "iter:11, loss:319.65983, time0.38107895851135254s\n",
      "iter:12, loss:319.64671, time0.4050731658935547s\n",
      "iter:13, loss:319.63796, time0.43776869773864746s\n",
      "iter:14, loss:319.6317, time0.47866010665893555s\n",
      "iter:15, loss:319.62686, time0.5086300373077393s\n",
      "iter:16, loss:319.62288, time0.531315803527832s\n",
      "iter:17, loss:319.6194, time0.5626020431518555s\n",
      "iter:18, loss:319.61624, time0.5938339233398438s\n",
      "iter:19, loss:319.61328, time0.6251332759857178s\n",
      "iter:20, loss:319.61044, time0.6543369293212891s\n",
      "iter:21, loss:319.60769, time0.6723229885101318s\n",
      "iter:22, loss:319.60498, time0.7048206329345703s\n",
      "iter:23, loss:319.60233, time0.7474179267883301s\n",
      "iter:24, loss:319.59973, time0.765488862991333s\n",
      "iter:25, loss:319.59717, time0.7967720031738281s\n",
      "iter:26, loss:319.59467, time0.8351759910583496s\n",
      "iter:27, loss:319.59222, time0.865046501159668s\n",
      "iter:28, loss:319.58983, time0.8905341625213623s\n",
      "iter:29, loss:319.58747, time0.9235439300537109s\n",
      "iter:30, loss:319.58516, time0.9633803367614746s\n",
      "iter:31, loss:319.58284, time0.9844532012939453s\n",
      "iter:32, loss:319.58053, time1.0313503742218018s\n",
      "iter:33, loss:319.57823, time1.0731532573699951s\n",
      "iter:34, loss:319.57604, time1.1043407917022705s\n",
      "iter:35, loss:319.57395, time1.1357543468475342s\n",
      "iter:36, loss:319.57197, time1.1722753047943115s\n",
      "iter:37, loss:319.57009, time1.2028520107269287s\n",
      "iter:38, loss:319.56834, time1.2340989112854004s\n",
      "iter:39, loss:319.56673, time1.2724788188934326s\n",
      "iter:40, loss:319.56527, time1.3085083961486816s\n",
      "iter:41, loss:319.56392, time1.3437986373901367s\n",
      "iter:42, loss:319.56269, time1.3813865184783936s\n",
      "iter:43, loss:319.56155, time1.4038400650024414s\n",
      "iter:44, loss:319.5605, time1.4507570266723633s\n",
      "iter:0, loss:319.55865, time0.016617298126220703s\n",
      "\n",
      "\n",
      " Topic is 10\n",
      "Counter({1.0: 210, 2.0: 97, 5.0: 79, 0.0: 77, 7.0: 70, 9.0: 60, 3.0: 46, 6.0: 36, 8.0: 33, 4.0: 29})\n",
      "----------------------------------------------------------------------------------------------------\n",
      "nmf_init\n",
      "iter:0, loss:326.0025, time0.02547764778137207s\n",
      "iter:1, loss:322.04644, time0.05676412582397461s\n",
      "iter:2, loss:319.53226, time0.09122109413146973s\n",
      "iter:3, loss:318.35062, time0.12426543235778809s\n",
      "iter:4, loss:317.88664, time0.15431475639343262s\n",
      "iter:5, loss:317.6769, time0.18546795845031738s\n",
      "iter:6, loss:317.55166, time0.21819400787353516s\n",
      "iter:7, loss:317.4624, time0.24909305572509766s\n",
      "iter:8, loss:317.39602, time0.2748539447784424s\n",
      "iter:9, loss:317.34944, time0.3060946464538574s\n",
      "iter:10, loss:317.31902, time0.33820247650146484s\n",
      "iter:11, loss:317.29962, time0.3555328845977783s\n",
      "iter:12, loss:317.28743, time0.3868129253387451s\n",
      "iter:13, loss:317.27941, time0.42757177352905273s\n",
      "iter:14, loss:317.27371, time0.4629848003387451s\n",
      "iter:15, loss:317.26934, time0.48992347717285156s\n",
      "iter:16, loss:317.26574, time0.5212092399597168s\n",
      "iter:17, loss:317.26258, time0.5565900802612305s\n",
      "iter:18, loss:317.25969, time0.5889654159545898s\n",
      "iter:19, loss:317.25694, time0.6201157569885254s\n",
      "iter:20, loss:317.25427, time0.6512546539306641s\n",
      "iter:21, loss:317.25163, time0.6858618259429932s\n",
      "iter:22, loss:317.249, time0.7180023193359375s\n",
      "iter:23, loss:317.24637, time0.7386302947998047s\n",
      "iter:24, loss:317.24374, time0.775484561920166s\n",
      "iter:25, loss:317.24113, time0.8067686557769775s\n",
      "iter:26, loss:317.23853, time0.8380134105682373s\n",
      "iter:27, loss:317.23597, time0.8757500648498535s\n",
      "iter:28, loss:317.23343, time0.9110722541809082s\n",
      "iter:29, loss:317.23092, time0.9515981674194336s\n",
      "iter:30, loss:317.22844, time0.988955020904541s\n",
      "iter:31, loss:317.22597, time1.0201992988586426s\n",
      "iter:32, loss:317.22351, time1.0514514446258545s\n",
      "iter:33, loss:317.22108, time1.0948805809020996s\n",
      "iter:34, loss:317.21873, time1.1326417922973633s\n",
      "iter:35, loss:317.2165, time1.1641860008239746s\n",
      "iter:36, loss:317.21437, time1.1943492889404297s\n",
      "iter:37, loss:317.21236, time1.223388671875s\n",
      "iter:38, loss:317.21049, time1.253499984741211s\n",
      "iter:39, loss:317.20876, time1.2751410007476807s\n",
      "iter:40, loss:317.20717, time1.311964750289917s\n",
      "iter:41, loss:317.20572, time1.3432862758636475s\n",
      "iter:42, loss:317.20438, time1.375983715057373s\n",
      "iter:43, loss:317.20314, time1.4051344394683838s\n",
      "iter:44, loss:317.202, time1.4350037574768066s\n",
      "iter:45, loss:317.20094, time1.461754560470581s\n",
      "iter:0, loss:317.19908, time0.03238224983215332s\n",
      "\n",
      "\n",
      " Topic is 11\n",
      "Counter({1.0: 170, 2.0: 97, 5.0: 78, 0.0: 72, 7.0: 69, 9.0: 61, 3.0: 47, 10.0: 47, 6.0: 36, 8.0: 32, 4.0: 28})\n",
      "----------------------------------------------------------------------------------------------------\n",
      "nmf_init\n",
      "iter:0, loss:324.66363, time0.03120732307434082s\n",
      "iter:1, loss:320.53825, time0.07079577445983887s\n",
      "iter:2, loss:317.95843, time0.10525155067443848s\n",
      "iter:3, loss:316.75777, time0.13574981689453125s\n",
      "iter:4, loss:316.26583, time0.15643668174743652s\n",
      "iter:5, loss:316.01462, time0.19683051109313965s\n",
      "iter:6, loss:315.8395, time0.23497891426086426s\n",
      "iter:7, loss:315.70123, time0.25438451766967773s\n",
      "iter:8, loss:315.58743, time0.28566408157348633s\n",
      "iter:9, loss:315.49147, time0.3271455764770508s\n",
      "iter:10, loss:315.40881, time0.34412455558776855s\n",
      "iter:11, loss:315.33778, time0.37540745735168457s\n",
      "iter:12, loss:315.27805, time0.4148092269897461s\n",
      "iter:13, loss:315.22836, time0.44420528411865234s\n",
      "iter:14, loss:315.18844, time0.47623705863952637s\n",
      "iter:15, loss:315.15642, time0.5044901371002197s\n",
      "iter:16, loss:315.13086, time0.5307021141052246s\n",
      "iter:17, loss:315.10934, time0.5776305198669434s\n",
      "iter:18, loss:315.09067, time0.6089189052581787s\n",
      "iter:19, loss:315.0745, time0.6397428512573242s\n",
      "iter:20, loss:315.06061, time0.6929903030395508s\n",
      "iter:21, loss:315.04892, time0.7289371490478516s\n",
      "iter:22, loss:315.03936, time0.7500295639038086s\n",
      "iter:23, loss:315.03169, time0.7922341823577881s\n",
      "iter:24, loss:315.02564, time0.8212344646453857s\n",
      "iter:25, loss:315.02097, time0.850039005279541s\n",
      "iter:26, loss:315.01741, time0.8792672157287598s\n",
      "iter:27, loss:315.01471, time0.9067564010620117s\n",
      "iter:28, loss:315.01271, time0.9428229331970215s\n",
      "iter:29, loss:315.01122, time0.9714651107788086s\n",
      "iter:30, loss:315.01011, time1.001943826675415s\n",
      "iter:0, loss:315.00864, time0.04109668731689453s\n",
      "\n",
      "\n",
      " Topic is 12\n",
      "Counter({1.0: 165, 2.0: 98, 5.0: 78, 7.0: 64, 9.0: 52, 10.0: 51, 3.0: 46, 11.0: 44, 0.0: 42, 6.0: 36, 8.0: 33, 4.0: 28})\n",
      "----------------------------------------------------------------------------------------------------\n",
      "nmf_init\n",
      "iter:0, loss:322.91307, time0.032137393951416016s\n",
      "iter:1, loss:318.75114, time0.06279897689819336s\n",
      "iter:2, loss:316.15816, time0.09564733505249023s\n",
      "iter:3, loss:314.93384, time0.1276721954345703s\n",
      "iter:4, loss:314.40177, time0.14705348014831543s\n",
      "iter:5, loss:314.08564, time0.1782670021057129s\n",
      "iter:6, loss:313.82551, time0.2205944061279297s\n",
      "iter:7, loss:313.59953, time0.2562565803527832s\n",
      "iter:8, loss:313.42275, time0.28173375129699707s\n",
      "iter:9, loss:313.29915, time0.3185596466064453s\n",
      "iter:10, loss:313.21763, time0.3483119010925293s\n",
      "iter:11, loss:313.16429, time0.37956786155700684s\n",
      "iter:12, loss:313.12836, time0.4094200134277344s\n",
      "iter:13, loss:313.10236, time0.4424705505371094s\n",
      "iter:14, loss:313.0826, time0.47521543502807617s\n",
      "iter:15, loss:313.06744, time0.5002458095550537s\n",
      "iter:16, loss:313.05582, time0.538646936416626s\n",
      "iter:17, loss:313.04698, time0.5703468322753906s\n",
      "iter:18, loss:313.04034, time0.6032016277313232s\n",
      "iter:19, loss:313.03542, time0.6353800296783447s\n",
      "iter:20, loss:313.03178, time0.6697628498077393s\n",
      "iter:21, loss:313.02913, time0.718498706817627s\n",
      "iter:22, loss:313.0272, time0.7468936443328857s\n",
      "iter:23, loss:313.02579, time0.7965271472930908s\n",
      "iter:24, loss:313.02477, time0.8325033187866211s\n",
      "iter:0, loss:313.02348, time0.031690359115600586s\n",
      "\n",
      "\n",
      " Topic is 13\n",
      "Counter({1.0: 166, 2.0: 97, 5.0: 78, 7.0: 64, 9.0: 53, 10.0: 49, 0.0: 43, 6.0: 37, 11.0: 35, 8.0: 32, 3.0: 30, 4.0: 28, 12.0: 25})\n",
      "----------------------------------------------------------------------------------------------------\n",
      "nmf_init\n",
      "iter:0, loss:321.72096, time0.03176546096801758s\n",
      "iter:1, loss:317.41454, time0.06658029556274414s\n",
      "iter:2, loss:314.8094, time0.09801888465881348s\n",
      "iter:3, loss:313.3425, time0.12297844886779785s\n",
      "iter:4, loss:312.57063, time0.1614391803741455s\n",
      "iter:5, loss:312.115, time0.18485331535339355s\n",
      "iter:6, loss:311.79668, time0.23469138145446777s\n",
      "iter:7, loss:311.56399, time0.26746535301208496s\n",
      "iter:8, loss:311.39251, time0.2831277847290039s\n",
      "iter:9, loss:311.26507, time0.32820940017700195s\n",
      "iter:10, loss:311.17139, time0.3469657897949219s\n",
      "iter:11, loss:311.1052, time0.3877828121185303s\n",
      "iter:12, loss:311.05817, time0.4232304096221924s\n",
      "iter:13, loss:311.02279, time0.45345377922058105s\n",
      "iter:14, loss:310.99461, time0.489879846572876s\n",
      "iter:15, loss:310.97182, time0.5211637020111084s\n",
      "iter:16, loss:310.95358, time0.5440540313720703s\n",
      "iter:17, loss:310.93917, time0.5861997604370117s\n",
      "iter:18, loss:310.92806, time0.6068720817565918s\n",
      "iter:19, loss:310.91972, time0.6522741317749023s\n",
      "iter:20, loss:310.9135, time0.6883354187011719s\n",
      "iter:21, loss:310.90894, time0.7227563858032227s\n",
      "iter:22, loss:310.90563, time0.7551608085632324s\n",
      "iter:23, loss:310.90322, time0.7789933681488037s\n",
      "iter:24, loss:310.90146, time0.8214225769042969s\n",
      "iter:25, loss:310.90018, time0.8420612812042236s\n",
      "iter:0, loss:310.89856, time0.035817861557006836s\n",
      "\n",
      "\n",
      " Topic is 14\n",
      "Counter({1.0: 159, 2.0: 97, 5.0: 78, 9.0: 50, 10.0: 47, 7.0: 42, 0.0: 40, 11.0: 37, 6.0: 37, 13.0: 35, 8.0: 33, 3.0: 30, 4.0: 28, 12.0: 24})\n",
      "----------------------------------------------------------------------------------------------------\n",
      "nmf_init\n",
      "iter:0, loss:320.056, time0.04586911201477051s\n",
      "iter:1, loss:315.56474, time0.0785989761352539s\n",
      "iter:2, loss:312.92402, time0.11056828498840332s\n",
      "iter:3, loss:311.42352, time0.14693117141723633s\n",
      "iter:4, loss:310.6328, time0.17158102989196777s\n",
      "iter:5, loss:310.16627, time0.22034358978271484s\n",
      "iter:6, loss:309.82773, time0.24934911727905273s\n",
      "iter:7, loss:309.56641, time0.2805931568145752s\n",
      "iter:8, loss:309.36755, time0.3118746280670166s\n",
      "iter:9, loss:309.2237, time0.3482646942138672s\n",
      "iter:10, loss:309.1235, time0.38021039962768555s\n",
      "iter:11, loss:309.0579, time0.4109814167022705s\n",
      "iter:12, loss:309.01433, time0.4424936771392822s\n",
      "iter:13, loss:308.98401, time0.4787158966064453s\n",
      "iter:14, loss:308.96249, time0.5063755512237549s\n",
      "iter:15, loss:308.94711, time0.5375785827636719s\n",
      "iter:16, loss:308.93617, time0.5688633918762207s\n",
      "iter:17, loss:308.92844, time0.6001057624816895s\n",
      "iter:18, loss:308.92303, time0.6239681243896484s\n",
      "iter:19, loss:308.91926, time0.6681368350982666s\n",
      "iter:20, loss:308.91664, time0.7013552188873291s\n",
      "iter:21, loss:308.91483, time0.7317488193511963s\n",
      "iter:22, loss:308.91357, time0.7507517337799072s\n",
      "iter:0, loss:308.91206, time0.032213687896728516s\n",
      "\n",
      "\n",
      " Topic is 15\n",
      "Counter({1.0: 131, 2.0: 96, 5.0: 77, 9.0: 49, 10.0: 48, 7.0: 42, 0.0: 41, 6.0: 37, 14.0: 36, 11.0: 36, 13.0: 36, 3.0: 30, 4.0: 28, 8.0: 25, 12.0: 25})\n",
      "----------------------------------------------------------------------------------------------------\n",
      "nmf_init\n",
      "iter:0, loss:318.04668, time0.032076358795166016s\n",
      "iter:1, loss:313.39175, time0.06387615203857422s\n",
      "iter:2, loss:310.61867, time0.09515762329101562s\n",
      "iter:3, loss:309.16203, time0.13358640670776367s\n",
      "iter:4, loss:308.46779, time0.16766071319580078s\n",
      "iter:5, loss:308.04545, time0.20051908493041992s\n",
      "iter:6, loss:307.72807, time0.2360219955444336s\n",
      "iter:7, loss:307.479, time0.26947665214538574s\n",
      "iter:8, loss:307.28713, time0.2896890640258789s\n",
      "iter:9, loss:307.14644, time0.3209190368652344s\n",
      "iter:10, loss:307.04782, time0.3592705726623535s\n",
      "iter:11, loss:306.98269, time0.4017782211303711s\n",
      "iter:12, loss:306.93903, time0.42459893226623535s\n",
      "iter:13, loss:306.9086, time0.4736964702606201s\n",
      "iter:14, loss:306.88706, time0.5083522796630859s\n",
      "iter:15, loss:306.87175, time0.5535714626312256s\n",
      "iter:16, loss:306.86092, time0.5795392990112305s\n",
      "iter:17, loss:306.85333, time0.6284613609313965s\n",
      "iter:18, loss:306.84805, time0.6570892333984375s\n",
      "iter:19, loss:306.84439, time0.6915788650512695s\n",
      "iter:20, loss:306.84187, time0.7330203056335449s\n",
      "iter:21, loss:306.84013, time0.7585339546203613s\n",
      "iter:22, loss:306.83892, time0.7974493503570557s\n",
      "iter:0, loss:306.83749, time0.026950359344482422s\n",
      "\n",
      "\n",
      " Topic is 16\n",
      "Counter({1.0: 130, 2.0: 96, 5.0: 54, 9.0: 49, 10.0: 48, 7.0: 42, 0.0: 40, 13.0: 37, 6.0: 37, 14.0: 36, 11.0: 36, 3.0: 30, 4.0: 27, 8.0: 25, 12.0: 25, 15.0: 25})\n",
      "----------------------------------------------------------------------------------------------------\n",
      "nmf_init\n",
      "iter:0, loss:316.397, time0.024910926818847656s\n",
      "iter:1, loss:311.39553, time0.07181024551391602s\n",
      "iter:2, loss:308.7932, time0.10718488693237305s\n",
      "iter:3, loss:307.44475, time0.1295619010925293s\n",
      "iter:4, loss:306.66261, time0.16373395919799805s\n",
      "iter:5, loss:306.18128, time0.1950058937072754s\n",
      "iter:6, loss:305.84207, time0.24769210815429688s\n",
      "iter:7, loss:305.58155, time0.28250837326049805s\n",
      "iter:8, loss:305.38258, time0.304044246673584s\n",
      "iter:9, loss:305.23706, time0.3353252410888672s\n",
      "iter:10, loss:305.13497, time0.3781139850616455s\n",
      "iter:11, loss:305.06696, time0.4175858497619629s\n",
      "iter:12, loss:305.02073, time0.4404025077819824s\n",
      "iter:13, loss:304.9881, time0.4880678653717041s\n",
      "iter:14, loss:304.96466, time0.5223419666290283s\n",
      "iter:15, loss:304.94765, time0.5531437397003174s\n",
      "iter:16, loss:304.93524, time0.5936391353607178s\n",
      "iter:17, loss:304.9262, time0.6290206909179688s\n",
      "iter:18, loss:304.91955, time0.6659753322601318s\n",
      "iter:19, loss:304.91461, time0.7039408683776855s\n",
      "iter:20, loss:304.91089, time0.741539478302002s\n",
      "iter:21, loss:304.90797, time0.7763855457305908s\n",
      "iter:22, loss:304.90559, time0.8076293468475342s\n",
      "iter:23, loss:304.90358, time0.8556008338928223s\n",
      "iter:24, loss:304.90185, time0.8944416046142578s\n",
      "iter:25, loss:304.90035, time0.9372744560241699s\n",
      "iter:26, loss:304.89901, time0.9774453639984131s\n",
      "iter:27, loss:304.89783, time1.0186882019042969s\n",
      "iter:28, loss:304.89678, time1.049973964691162s\n",
      "iter:0, loss:304.89497, time0.0341792106628418s\n",
      "\n",
      "\n",
      " Topic is 17\n",
      "Counter({1.0: 130, 2.0: 72, 5.0: 54, 9.0: 49, 10.0: 47, 7.0: 42, 0.0: 38, 6.0: 38, 14.0: 37, 13.0: 37, 11.0: 36, 3.0: 30, 16.0: 26, 4.0: 26, 8.0: 25, 12.0: 25, 15.0: 25})\n",
      "----------------------------------------------------------------------------------------------------\n",
      "nmf_init\n",
      "iter:0, loss:315.14282, time0.035607337951660156s\n",
      "iter:1, loss:309.87201, time0.06349897384643555s\n",
      "iter:2, loss:307.17555, time0.1059730052947998s\n",
      "iter:3, loss:305.78884, time0.12660598754882812s\n",
      "iter:4, loss:305.02708, time0.17350172996520996s\n",
      "iter:5, loss:304.59255, time0.21222877502441406s\n",
      "iter:6, loss:304.3046, time0.24929261207580566s\n",
      "iter:7, loss:304.07664, time0.28437232971191406s\n",
      "iter:8, loss:303.8655, time0.3136763572692871s\n",
      "iter:9, loss:303.65543, time0.35352611541748047s\n",
      "iter:10, loss:303.4618, time0.37614917755126953s\n",
      "iter:11, loss:303.30976, time0.42301154136657715s\n",
      "iter:12, loss:303.2021, time0.45438385009765625s\n",
      "iter:13, loss:303.12942, time0.4946012496948242s\n",
      "iter:14, loss:303.08187, time0.5278868675231934s\n",
      "iter:15, loss:303.05128, time0.5653829574584961s\n",
      "iter:16, loss:303.03137, time0.5944304466247559s\n",
      "iter:17, loss:303.01798, time0.6257200241088867s\n",
      "iter:18, loss:303.00869, time0.678156852722168s\n",
      "iter:19, loss:303.00204, time0.7125141620635986s\n",
      "iter:20, loss:302.99715, time0.7437982559204102s\n",
      "iter:21, loss:302.99346, time0.7906606197357178s\n",
      "iter:22, loss:302.99055, time0.8219068050384521s\n",
      "iter:23, loss:302.98814, time0.8720338344573975s\n",
      "iter:24, loss:302.98609, time0.9191021919250488s\n",
      "iter:25, loss:302.98433, time0.9458394050598145s\n",
      "iter:26, loss:302.9828, time0.9992063045501709s\n",
      "iter:27, loss:302.98145, time1.0324828624725342s\n",
      "iter:28, loss:302.98026, time1.0637259483337402s\n",
      "iter:29, loss:302.97922, time1.10239839553833s\n",
      "iter:0, loss:302.97744, time0.03563237190246582s\n",
      "\n",
      "\n",
      " Topic is 18\n",
      "Counter({17.0: 99, 2.0: 72, 1.0: 64, 5.0: 52, 9.0: 49, 10.0: 45, 7.0: 41, 6.0: 36, 11.0: 34, 13.0: 34, 3.0: 30, 0.0: 29, 16.0: 26, 4.0: 26, 8.0: 26, 12.0: 25, 15.0: 25, 14.0: 24})\n",
      "----------------------------------------------------------------------------------------------------\n",
      "nmf_init\n",
      "iter:0, loss:313.8826, time0.031089067459106445s\n",
      "iter:1, loss:308.20194, time0.062372446060180664s\n",
      "iter:2, loss:305.40614, time0.10785961151123047s\n",
      "iter:3, loss:303.99689, time0.14030694961547852s\n",
      "iter:4, loss:303.24519, time0.1715869903564453s\n",
      "iter:5, loss:302.83626, time0.22021150588989258s\n",
      "iter:6, loss:302.58817, time0.25789570808410645s\n",
      "iter:7, loss:302.40624, time0.2923250198364258s\n",
      "iter:8, loss:302.24158, time0.3266103267669678s\n",
      "iter:9, loss:302.06899, time0.35954785346984863s\n",
      "iter:10, loss:301.89314, time0.3908367156982422s\n",
      "iter:11, loss:301.74068, time0.4325835704803467s\n",
      "iter:12, loss:301.62635, time0.47243809700012207s\n",
      "iter:13, loss:301.54586, time0.49890971183776855s\n",
      "iter:14, loss:301.49151, time0.5441834926605225s\n",
      "iter:15, loss:301.45571, time0.5775291919708252s\n",
      "iter:16, loss:301.43181, time0.6088151931762695s\n",
      "iter:17, loss:301.4152, time0.6560277938842773s\n",
      "iter:18, loss:301.40319, time0.6947023868560791s\n",
      "iter:19, loss:301.39413, time0.731001615524292s\n",
      "iter:20, loss:301.38707, time0.7706212997436523s\n",
      "iter:21, loss:301.38145, time0.8077661991119385s\n",
      "iter:22, loss:301.37691, time0.8501260280609131s\n",
      "iter:23, loss:301.37316, time0.8843040466308594s\n",
      "iter:24, loss:301.37, time0.9326357841491699s\n",
      "iter:25, loss:301.36728, time0.96388840675354s\n",
      "iter:26, loss:301.3649, time1.0144717693328857s\n",
      "iter:27, loss:301.36282, time1.0470190048217773s\n",
      "iter:28, loss:301.36099, time1.081716775894165s\n",
      "iter:29, loss:301.35937, time1.1186854839324951s\n",
      "iter:30, loss:301.35794, time1.1496312618255615s\n",
      "iter:31, loss:301.35667, time1.1808815002441406s\n",
      "iter:32, loss:301.35554, time1.212122917175293s\n",
      "iter:33, loss:301.35454, time1.25044584274292s\n",
      "iter:0, loss:301.35277, time0.03397846221923828s\n",
      "\n",
      "\n",
      " Topic is 19\n",
      "Counter({17.0: 89, 2.0: 70, 1.0: 59, 5.0: 52, 9.0: 49, 7.0: 42, 10.0: 42, 6.0: 36, 11.0: 35, 13.0: 33, 3.0: 30, 16.0: 27, 4.0: 26, 0.0: 26, 8.0: 26, 12.0: 25, 15.0: 25, 14.0: 23, 18.0: 22})\n",
      "----------------------------------------------------------------------------------------------------\n",
      "nmf_init\n",
      "iter:0, loss:312.89556, time0.03690814971923828s\n",
      "iter:1, loss:306.82903, time0.07304644584655762s\n",
      "iter:2, loss:303.90004, time0.10920977592468262s\n",
      "iter:3, loss:302.47783, time0.14460515975952148s\n",
      "iter:4, loss:301.72522, time0.17421817779541016s\n",
      "iter:5, loss:301.30741, time0.2201521396636963s\n",
      "iter:6, loss:301.04087, time0.26072120666503906s\n",
      "iter:7, loss:300.84185, time0.28480076789855957s\n",
      "iter:8, loss:300.66854, time0.3330981731414795s\n",
      "iter:9, loss:300.49198, time0.3679344654083252s\n",
      "iter:10, loss:300.30803, time0.39183688163757324s\n",
      "iter:11, loss:300.1313, time0.44076085090637207s\n",
      "iter:12, loss:299.98095, time0.47870922088623047s\n",
      "iter:13, loss:299.85982, time0.5187370777130127s\n",
      "iter:14, loss:299.76692, time0.5546731948852539s\n",
      "iter:15, loss:299.6993, time0.5916986465454102s\n",
      "iter:16, loss:299.65171, time0.6330010890960693s\n",
      "iter:17, loss:299.6187, time0.6836936473846436s\n",
      "iter:18, loss:299.59585, time0.7206947803497314s\n",
      "iter:19, loss:299.57992, time0.7670834064483643s\n",
      "iter:20, loss:299.56873, time0.8021628856658936s\n",
      "iter:21, loss:299.56108, time0.830141544342041s\n",
      "iter:22, loss:299.55574, time0.870532751083374s\n",
      "iter:23, loss:299.55191, time0.9065561294555664s\n",
      "iter:24, loss:299.54916, time0.9454529285430908s\n",
      "iter:25, loss:299.54714, time0.9670827388763428s\n",
      "iter:26, loss:299.54562, time1.015026569366455s\n",
      "iter:27, loss:299.54445, time1.0488581657409668s\n",
      "iter:0, loss:299.54283, time0.03623843193054199s\n",
      "\n",
      "\n",
      " Topic is 20\n",
      "Counter({17.0: 92, 1.0: 57, 16.0: 51, 5.0: 51, 9.0: 49, 2.0: 47, 10.0: 42, 7.0: 41, 6.0: 36, 11.0: 34, 13.0: 34, 3.0: 29, 0.0: 26, 8.0: 26, 12.0: 25, 15.0: 24, 14.0: 23, 18.0: 20, 4.0: 17, 19.0: 13})\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for j in range(2,21):  #topics\n",
    "    H_nnsvd, W_nnsvd = nndsvd(tv_fit.toarray(), j)\n",
    "    # print(W_nnsvd.shape,H_nnsvd.shape)\n",
    "    model = NMF(\n",
    "        X, \n",
    "        n_topic=j,\n",
    "        max_iter=max_iter, \n",
    "        max_err=max_err,rand_init=False, IW=W_nnsvd.T,IH=H_nnsvd)\n",
    "\n",
    "    model.nmf_iter()\n",
    "    W,H=model.return_weight()\n",
    "    nmf_pred=np.zeros(H.shape[0])\n",
    "    for index,value in enumerate(H):\n",
    "        nmf_pred[index]=list(value).index(np.max(value))\n",
    "    print('\\n\\n',f'Topic is {j}') \n",
    "    print(Counter(nmf_pred))\n",
    "    name='topic'+str(j)\n",
    "    data_initial.insert(j+1, name, nmf_pred.astype(int))\n",
    "    print('--'*50)\n",
    "data_initial.to_excel(path,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "88e204e1-d4b3-49c1-bb30-39128ddb3965",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_initial.to_excel(path,index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6114371f-2e01-4bc4-b9ab-d738a5077703",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# SeaNMF short text "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "0655f6f1-e853-47cc-90b7-d015469c783f",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_iter=100\n",
    "# n_topics=5\n",
    "alpha=1.0\n",
    "beta=0.1\n",
    "max_err=1e-3\n",
    "fix_seed=np.random.seed(0)\n",
    "X=tv_fit.toarray().T\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "7144cb00-bbd5-47e2-b77d-7a4412433441",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4607, 5) (4607, 5) (7409, 5) (4607, 7409)\n",
      "loop begin\n",
      "Step=0, Loss=2984323.0999932904, Time=1.1982970237731934s\n",
      "Step=1, Loss=2948516.1537592267, Time=2.2294046878814697s\n",
      "Step=2, Loss=2921080.8203444136, Time=3.1541669368743896s\n",
      "Step=3, Loss=2897106.5617011855, Time=4.0312864780426025s\n",
      "Step=4, Loss=2884448.6208720887, Time=4.910534381866455s\n",
      "Step=5, Loss=2877602.9145164425, Time=5.772297620773315s\n",
      "Step=6, Loss=2874438.7829573588, Time=6.613667726516724s\n",
      "Step=7, Loss=2872999.65184529, Time=7.501529932022095s\n",
      "Step=8, Loss=2872274.1346848207, Time=8.454342603683472s\n",
      "Step=9, Loss=2871879.002158072, Time=9.311069011688232s\n",
      "Step=10, Loss=2871650.8148790365, Time=10.202889680862427s\n",
      "Step=11, Loss=2871510.6369883013, Time=11.125685214996338s\n",
      "Step=12, Loss=2871419.394813475, Time=12.030350685119629s\n",
      "Step=13, Loss=2871356.89767605, Time=12.872650861740112s\n",
      "Step=14, Loss=2871312.0473810756, Time=13.687061071395874s\n",
      "Step=15, Loss=2871278.6100794934, Time=14.575299978256226s\n",
      "Step=16, Loss=2871253.0360074313, Time=15.670650005340576s\n",
      "Step=17, Loss=2871233.103694185, Time=16.517412424087524s\n",
      "Step=18, Loss=2871217.3903436284, Time=17.345792770385742s\n",
      "Step=19, Loss=2871204.93979345, Time=18.29881739616394s\n",
      "Step=20, Loss=2871194.9900159063, Time=19.13509774208069s\n",
      "Step=21, Loss=2871186.9873448415, Time=19.96520495414734s\n",
      "Step=22, Loss=2871180.502460154, Time=20.848292589187622s\n",
      "Step=23, Loss=2871175.2180600236, Time=21.779189109802246s\n",
      "Step=24, Loss=2871170.8863322567, Time=22.693140983581543s\n",
      "Step=25, Loss=2871167.320244422, Time=23.632254362106323s\n",
      "Step=26, Loss=2871164.367428129, Time=24.72111678123474s\n",
      "Step=27, Loss=2871161.908460244, Time=25.66315460205078s\n",
      "Step=28, Loss=2871159.851719311, Time=26.516607999801636s\n",
      "Step=29, Loss=2871158.12693062, Time=27.377628564834595s\n",
      "Step=30, Loss=2871156.6759674163, Time=28.217241525650024s\n",
      "Step=31, Loss=2871155.4532214985, Time=29.130983114242554s\n",
      "Step=32, Loss=2871154.420864961, Time=29.965076208114624s\n",
      "Step=33, Loss=2871153.54826772, Time=31.03127694129944s\n",
      "Step=34, Loss=2871152.809240074, Time=32.008612871170044s\n",
      "Step=35, Loss=2871152.18124383, Time=32.83186626434326s\n",
      "Step=36, Loss=2871151.6463325527, Time=33.730915784835815s\n",
      "Step=37, Loss=2871151.189881287, Time=34.56852960586548s\n",
      "Step=38, Loss=2871150.7996631735, Time=35.65636587142944s\n",
      "Step=39, Loss=2871150.4655598784, Time=36.52086687088013s\n",
      "Step=40, Loss=2871150.179040806, Time=37.413907051086426s\n",
      "Step=41, Loss=2871149.9328119014, Time=38.34690713882446s\n",
      "Step=42, Loss=2871149.7208296233, Time=39.16410493850708s\n",
      "Step=43, Loss=2871149.5382172177, Time=40.062912940979004s\n",
      "Step=44, Loss=2871149.3808838404, Time=41.13052225112915s\n",
      "Step=45, Loss=2871149.2451853096, Time=42.232093334198s\n",
      "Step=46, Loss=2871149.128043284, Time=43.321924924850464s\n",
      "Step=47, Loss=2871149.026815921, Time=44.2610502243042s\n",
      "Step=48, Loss=2871148.9393399414, Time=45.139431953430176s\n",
      "Step=49, Loss=2871148.863661487, Time=46.03488516807556s\n",
      "Step=50, Loss=2871148.7981456975, Time=46.90731859207153s\n",
      "Step=51, Loss=2871148.7415498383, Time=47.738991022109985s\n",
      "Step=52, Loss=2871148.692541942, Time=48.59820365905762s\n",
      "Step=53, Loss=2871148.650034029, Time=49.43741846084595s\n",
      "Step=54, Loss=2871148.613145142, Time=50.29806590080261s\n",
      "Step=55, Loss=2871148.581094798, Time=51.15244674682617s\n",
      "Step=56, Loss=2871148.5532033653, Time=52.16285419464111s\n",
      "Step=57, Loss=2871148.528897384, Time=52.99641799926758s\n",
      "Step=58, Loss=2871148.5076888017, Time=53.881733894348145s\n",
      "Step=59, Loss=2871148.4891671995, Time=54.72910022735596s\n",
      "Step=60, Loss=2871148.4729637653, Time=55.597479581832886s\n",
      "Step=61, Loss=2871148.458766213, Time=56.44938063621521s\n",
      "Step=62, Loss=2871148.44630328, Time=57.325427770614624s\n",
      "Step=63, Loss=2871148.4353491287, Time=58.29493165016174s\n",
      "Step=64, Loss=2871148.425707411, Time=59.25943040847778s\n",
      "Step=65, Loss=2871148.41720652, Time=60.12946915626526s\n",
      "Step=66, Loss=2871148.409696923, Time=61.01397514343262s\n",
      "Step=67, Loss=2871148.403052002, Time=61.96868586540222s\n",
      "Step=68, Loss=2871148.3971633078, Time=62.787872314453125s\n",
      "Step=69, Loss=2871148.391936482, Time=63.6700234413147s\n",
      "Step=70, Loss=2871148.387289211, Time=64.54800271987915s\n",
      "Step=71, Loss=2871148.383150819, Time=65.4279842376709s\n",
      "Step=72, Loss=2871148.379460041, Time=66.28746151924133s\n",
      "Step=73, Loss=2871148.3761634463, Time=67.22400379180908s\n",
      "Step=74, Loss=2871148.373214612, Time=68.06413459777832s\n",
      "Step=75, Loss=2871148.370573085, Time=69.05605483055115s\n",
      "Step=76, Loss=2871148.368203466, Time=70.07259607315063s\n",
      "Step=77, Loss=2871148.3660747833, Time=71.03437447547913s\n",
      "Step=78, Loss=2871148.364160104, Time=71.97337746620178s\n",
      "Step=79, Loss=2871148.362435593, Time=72.7725031375885s\n",
      "Step=80, Loss=2871148.360880422, Time=73.71946668624878s\n",
      "Step=81, Loss=2871148.359476141, Time=74.60311365127563s\n",
      "Step=82, Loss=2871148.3582067173, Time=75.63526678085327s\n",
      "Step=83, Loss=2871148.3570579225, Time=76.82823085784912s\n",
      "Step=84, Loss=2871148.3560170894, Time=77.86897230148315s\n",
      "(4607, 5) (4607, 5) (7409, 5)\n",
      "\n",
      "\n",
      " Topic is 5\n",
      "Counter({0.0: 1899, 4.0: 1748, 1.0: 1527, 2.0: 1236, 3.0: 999})\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "cannot insert topic5, already exists",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [145]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28mprint\u001b[39m(Counter(seanmf))\n\u001b[0;32m     19\u001b[0m name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtopic\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mstr\u001b[39m(j)\n\u001b[1;32m---> 20\u001b[0m \u001b[43mdata_initial\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minsert\u001b[49m\u001b[43m(\u001b[49m\u001b[43mj\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseanmf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m--\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m50\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\frame.py:4772\u001b[0m, in \u001b[0;36mDataFrame.insert\u001b[1;34m(self, loc, column, value, allow_duplicates)\u001b[0m\n\u001b[0;32m   4766\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   4767\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot specify \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mallow_duplicates=True\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m when \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   4768\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mself.flags.allows_duplicate_labels\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is False.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   4769\u001b[0m     )\n\u001b[0;32m   4770\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m allow_duplicates \u001b[38;5;129;01mand\u001b[39;00m column \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns:\n\u001b[0;32m   4771\u001b[0m     \u001b[38;5;66;03m# Should this be a different kind of error??\u001b[39;00m\n\u001b[1;32m-> 4772\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcannot insert \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcolumn\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, already exists\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   4773\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(loc, \u001b[38;5;28mint\u001b[39m):\n\u001b[0;32m   4774\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloc must be int\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: cannot insert topic5, already exists"
     ]
    }
   ],
   "source": [
    "for j in range(2,21):  #topics\n",
    "    model = SeaNMF(\n",
    "        X, SS,  \n",
    "        alpha=alpha, \n",
    "        beta=beta, \n",
    "        n_topic=j, \n",
    "        max_iter=max_iter, \n",
    "        max_err=max_err,\n",
    "        fix_seed=fix_seed)\n",
    "    \n",
    "    W1,W2,H=model.return_weight()\n",
    "    print(W1.shape,W2.shape,H.shape)\n",
    "    \n",
    "    seanmf=np.zeros(H.shape[0])\n",
    "    for index,value in enumerate(H):\n",
    "        seanmf[index]=list(value).index(np.max(value))\n",
    "    print('\\n\\n',f'Topic is {j}') \n",
    "    print(Counter(seanmf))\n",
    "    name='topic'+str(j)\n",
    "    data_initial.insert(j+1, name, seanmf.astype(int))\n",
    "    print('--'*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "ce677c23-cdb3-4879-96c7-3fc837f13bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_initial.to_excel(path,index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cefc0dde-3717-44c9-b8de-22306bd20b8b",
   "metadata": {},
   "source": [
    "# LDA long text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "80f54f0c-62ff-4f1d-b743-2efd6b4b0cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation as LDA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9aafd5a6-e171-4222-a0c8-517e87be3975",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " Topic is 4\n",
      "Counter({1: 427, 2: 400, 0: 313, 3: 259})\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "matrix=dt_mat\n",
    "for j in range(2,21):\n",
    "    lda=LDA(n_components=j, \n",
    "             max_iter=50,\n",
    "             learning_method='batch',    \n",
    "             learning_offset=50,\n",
    "             # doc_topic_prior=0.1,\n",
    "             # topic_word_prior=0.01,\n",
    "             random_state=0)\n",
    "    lda.fit(matrix)\n",
    "    topics=lda.transform(matrix)  \n",
    "    topic=[]\n",
    "    for i in topics:\n",
    "        topic.append(list(i).index(np.max(i)))  \n",
    "    print('\\n\\n',f'Topic is {j}') \n",
    "    print(Counter(topic))\n",
    "    name='topic'+str(j)\n",
    "    data_initial.insert(j+1, name, topic)\n",
    "    print('--'*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e86608fb-efd7-4d04-8ab1-5699b71a1054",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_initial.to_excel(path,index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8be9a1a-c4b9-4ed0-b586-4c5af9d6e2f8",
   "metadata": {},
   "source": [
    "# GSDMM short text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6b41fa64-a194-4d02-92af-adcfb0ede488",
   "metadata": {},
   "outputs": [],
   "source": [
    "#gsdmm\n",
    "from numpy.random import multinomial\n",
    "from numpy import log, exp\n",
    "from numpy import argmax\n",
    "import json\n",
    "\n",
    "class MovieGroupProcess:\n",
    "    def __init__(self, K=8, alpha=0.1, beta=0.1, n_iters=30):\n",
    "        '''\n",
    "        Reference: http://dbgroup.cs.tsinghua.edu.cn/wangjy/papers/KDD14-GSDMM.pdf\n",
    "        \n",
    "        :param K: int\n",
    "            Upper bound on the number of possible clusters. Typically many fewer\n",
    "        :param alpha: float between 0 and 1\n",
    "            Alpha controls the probability that a student will join a table that is currently empty\n",
    "            When alpha is 0, no one will join an empty table.\n",
    "        :param beta: float between 0 and 1\n",
    "            Beta controls the student's affinity for other students with similar interests. A low beta means\n",
    "            that students desire to sit with students of similar interests. A high beta means they are less\n",
    "            concerned with affinity and are more influenced by the popularity of a table\n",
    "        :param n_iters:\n",
    "        '''\n",
    "        self.K = K\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "        self.n_iters = n_iters\n",
    "\n",
    "        # slots for computed variables\n",
    "        self.number_docs = None\n",
    "        self.vocab_size = None\n",
    "        self.cluster_doc_count = [0 for _ in range(K)]\n",
    "        self.cluster_word_count = [0 for _ in range(K)]\n",
    "        self.cluster_word_distribution = [{} for i in range(K)]\n",
    "\n",
    "    @staticmethod\n",
    "    def _sample(p):\n",
    "        '''\n",
    "        Sample with probability vector p from a multinomial distribution\n",
    "        :param p: list\n",
    "            List of probabilities representing probability vector for the multinomial distribution\n",
    "        :return: int\n",
    "            index of randomly selected output\n",
    "        '''\n",
    "        return [i for i, entry in enumerate(multinomial(1, p)) if entry != 0][0]\n",
    "\n",
    "    def fit(self, docs, vocab_size):\n",
    "        '''\n",
    "        Cluster the input documents\n",
    "        :param docs: list of list\n",
    "            list of lists containing the unique token set of each document\n",
    "        :param V: total vocabulary size for each document\n",
    "        :return: list of length len(doc)\n",
    "            cluster label for each document\n",
    "        '''\n",
    "        alpha, beta, K, n_iters, V = self.alpha, self.beta, self.K, self.n_iters, vocab_size\n",
    "\n",
    "        D = len(docs)\n",
    "        self.number_docs = D\n",
    "        self.vocab_size = vocab_size\n",
    "\n",
    "        # unpack to easy var names\n",
    "        # mz number of documents in cluster z \n",
    "        # nz number of words in cluster z   \n",
    "        # nwz number of occurrences of word w in cluster z  \n",
    "        m_z, n_z, n_z_w = self.cluster_doc_count, self.cluster_word_count, self.cluster_word_distribution\n",
    "        cluster_count = K\n",
    "\n",
    "        d_z = [None for i in range(len(docs))]\n",
    "        \n",
    "        # initialize the clusters\n",
    "\n",
    "        for i, doc in enumerate(docs):\n",
    "            # choose a random  initial cluster for the doc\n",
    "            z = self._sample([1.0 / K for _ in range(K)])\n",
    "            d_z[i] = z  \n",
    "            m_z[z] += 1  \n",
    "            n_z[z] += len(doc)\n",
    "            \n",
    "            for word in doc:\n",
    "                if word not in n_z_w[z]:\n",
    "                    n_z_w[z][word] = 0  \n",
    "                n_z_w[z][word] += 1   \n",
    "        # print(n_z_w[0])\n",
    "        # print(n_z[0])\n",
    "        for _iter in range(n_iters):\n",
    "            total_transfers = 0\n",
    "            for i, doc in enumerate(docs):\n",
    "                \n",
    "                # remove the doc from it's current cluster\n",
    "                z_old = d_z[i]\n",
    "                m_z[z_old] -= 1 \n",
    "                n_z[z_old] -= len(doc)\n",
    "                for word in doc:\n",
    "\n",
    "                    n_z_w[z_old][word] -= 1   \n",
    "                    # compact dictionary to save space\n",
    "                    if n_z_w[z_old][word] == 0:  \n",
    "                        del n_z_w[z_old][word]\n",
    "\n",
    "                # draw sample from distribution to find new cluster\n",
    "                p = self.score(doc)\n",
    "                z_new = self._sample(p)  \n",
    "\n",
    "                # transfer doc to the new cluster\n",
    "                if z_new != z_old:\n",
    "                    total_transfers += 1\n",
    "                #ÂÖàÂáèÂêéÂä†\n",
    "                d_z[i] = z_new\n",
    "                m_z[z_new] += 1\n",
    "                n_z[z_new] += len(doc)\n",
    "                for word in doc:\n",
    "                    if word not in n_z_w[z_new]:\n",
    "                        n_z_w[z_new][word] = 0\n",
    "                    n_z_w[z_new][word] += 1\n",
    "\n",
    "            cluster_count_new = sum([1 for v in m_z if v > 0])\n",
    "            print(\"In stage %d: transferred %d clusters with %d clusters populated\" % (\n",
    "            _iter, total_transfers, cluster_count_new))\n",
    "            if total_transfers == 0 and cluster_count_new == cluster_count and _iter>25:\n",
    "                print(\"Converged.  Breaking out.\")\n",
    "                break\n",
    "            cluster_count = cluster_count_new\n",
    "        self.cluster_word_distribution = n_z_w\n",
    "        return d_z\n",
    "\n",
    "    def score(self, doc):\n",
    "        '''\n",
    "        Score a document\n",
    "\n",
    "        Implements formula (3) of Yin and Wang 2014.\n",
    "        http://dbgroup.cs.tsinghua.edu.cn/wangjy/papers/KDD14-GSDMM.pdf\n",
    "\n",
    "        :param doc: list[str]: The doc token stream\n",
    "        :return: list[float]: A length K probability vector where each component represents\n",
    "                              the probability of the document appearing in a particular cluster\n",
    "        '''\n",
    "        alpha, beta, K, V, D = self.alpha, self.beta, self.K, self.vocab_size, self.number_docs\n",
    "        m_z, n_z, n_z_w = self.cluster_doc_count, self.cluster_word_count, self.cluster_word_distribution\n",
    "        p = [0 for _ in range(K)]\n",
    "        #  We break the formula into the following pieces\n",
    "        #  p = N1*N2/(D1*D2) = exp(lN1 - lD1 + lN2 - lD2)\n",
    "        #  lN1 = log(m_z[z] + alpha)\n",
    "        #  lN2 = log(D - 1 + K*alpha)\n",
    "        #  lN2 = log(product(n_z_w[w] + beta)) = sum(log(n_z_w[w] + beta))\n",
    "        #  lD2 = log(product(n_z[d] + V*beta + i -1)) = sum(log(n_z[d] + V*beta + i -1))\n",
    "\n",
    "        lD1 = log(D - 1 + K * alpha)\n",
    "        doc_size = len(doc)\n",
    "        for label in range(K):   \n",
    "            lN1 = log(m_z[label] + alpha)  \n",
    "            lN2 = 0\n",
    "            lD2 = 0\n",
    "            for word in doc:\n",
    "                lN2 += log(n_z_w[label].get(word, 0) + beta) \n",
    "            for j in range(1, doc_size +1):\n",
    "                lD2 += log(n_z[label] + V * beta + j - 1)     \n",
    "            p[label] = exp(lN1 - lD1 + lN2 - lD2)\n",
    "\n",
    "        # normalize the probability vector\n",
    "        pnorm = sum(p)\n",
    "        pnorm = pnorm if pnorm>0 else 1\n",
    "        return [pp/pnorm for pp in p]\n",
    "\n",
    "    def choose_best_label(self, doc):\n",
    "        '''\n",
    "        Choose the highest probability label for the input document\n",
    "        :param doc: list[str]: The doc token stream\n",
    "        :return:\n",
    "        '''\n",
    "        p = self.score(doc)\n",
    "        return argmax(p),max(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d99aab0e-35b3-4bd2-87c2-18d616769e81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In stage 0: transferred 4691 clusters with 4 clusters populated\n",
      "In stage 1: transferred 2619 clusters with 4 clusters populated\n",
      "In stage 2: transferred 1277 clusters with 4 clusters populated\n",
      "In stage 3: transferred 697 clusters with 4 clusters populated\n",
      "In stage 4: transferred 425 clusters with 4 clusters populated\n",
      "In stage 5: transferred 309 clusters with 4 clusters populated\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [22]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m4\u001b[39m,\u001b[38;5;241m21\u001b[39m):\n\u001b[0;32m      3\u001b[0m     gsdmm \u001b[38;5;241m=\u001b[39m MovieGroupProcess(K\u001b[38;5;241m=\u001b[39mj, alpha\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m, beta\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m, n_iters\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m30\u001b[39m)\n\u001b[1;32m----> 4\u001b[0m     topic \u001b[38;5;241m=\u001b[39m \u001b[43mgsdmm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_matrix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mvocab_arr\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTopic is \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mj\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m) \n\u001b[0;32m      6\u001b[0m     \u001b[38;5;28mprint\u001b[39m(Counter(topic))\n",
      "Input \u001b[1;32mIn [4]\u001b[0m, in \u001b[0;36mMovieGroupProcess.fit\u001b[1;34m(self, docs, vocab_size)\u001b[0m\n\u001b[0;32m     98\u001b[0m         \u001b[38;5;28;01mdel\u001b[39;00m n_z_w[z_old][word]\n\u001b[0;32m    100\u001b[0m \u001b[38;5;66;03m# draw sample from distribution to find new cluster\u001b[39;00m\n\u001b[1;32m--> 101\u001b[0m p \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscore\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdoc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    102\u001b[0m z_new \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sample(p)  \n\u001b[0;32m    104\u001b[0m \u001b[38;5;66;03m# transfer doc to the new cluster\u001b[39;00m\n",
      "Input \u001b[1;32mIn [4]\u001b[0m, in \u001b[0;36mMovieGroupProcess.score\u001b[1;34m(self, doc)\u001b[0m\n\u001b[0;32m    152\u001b[0m lD2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m    153\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m doc:\n\u001b[1;32m--> 154\u001b[0m     lN2 \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m log(n_z_w[label]\u001b[38;5;241m.\u001b[39mget(word, \u001b[38;5;241m0\u001b[39m) \u001b[38;5;241m+\u001b[39m beta) \n\u001b[0;32m    155\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, doc_size \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m    156\u001b[0m     lD2 \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m log(n_z[label] \u001b[38;5;241m+\u001b[39m V \u001b[38;5;241m*\u001b[39m beta \u001b[38;5;241m+\u001b[39m j \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m)     \n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import random\n",
    "for j in range(2,21):\n",
    "    gsdmm = MovieGroupProcess(K=j, alpha=0.1, beta=0.1, n_iters=30)\n",
    "    topic = gsdmm.fit(data_matrix, len(vocab_arr))\n",
    "    print('\\n\\n',f'Topic is {j}') \n",
    "    print(Counter(topic))\n",
    "    name='topic'+str(j)\n",
    "    # data_initial.insert(j+1, name, topic)\n",
    "    print('--'*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7413e2b3-9081-421d-93fb-c03cf6883753",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_initial.to_excel(path,index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa11076d-748a-4a7f-be45-e297dffa1f4d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# NNDSVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8c72e85b-8bbe-4892-ab4a-984a7dda33b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# functions to extract positive and negative part\n",
    "def pos(vec):\n",
    "  return np.array(list(map(lambda x: max(x, 0), vec)))\n",
    "\n",
    "def neg(vec):\n",
    "  return np.array(list(map(lambda x: max(-x, 0), vec)))\n",
    "\n",
    "def normalize(vec):\n",
    "  return vec / np.linalg.norm(vec)\n",
    "\n",
    "def nndsvd(A, k):\n",
    "  # here we will assume k < rank(A)\n",
    "  # Get shape of A\n",
    "  m, n = A.shape\n",
    "\n",
    "  # conduct SVD\n",
    "  U, S, V = np.linalg.svd(A, full_matrices = False)\n",
    "\n",
    "  # store resulting matrix\n",
    "  W, H = np.zeros((m, k)), np.zeros((k, n))\n",
    "\n",
    "  # update rows and columns of W and H\n",
    "  for i in range(k):\n",
    "    if i == 0:\n",
    "      W[:, 0] = np.sqrt(S[0]) * np.abs(U[:, 0])\n",
    "      H[0, :] = np.sqrt(S[0]) * np.abs(V[0, :])\n",
    "    else:\n",
    "      x = U[:, i]\n",
    "      y = V[i, :]\n",
    "      xp, xn = pos(x), neg(x)\n",
    "      yp, yn = pos(y), neg(y)\n",
    "      if np.linalg.norm(xp) * np.linalg.norm(yp) > np.linalg.norm(xn) * np.linalg.norm(yn):\n",
    "        u = normalize(xp)\n",
    "        v = normalize(yp)\n",
    "        sigma = np.linalg.norm(xp) * np.linalg.norm(yp)\n",
    "      else:\n",
    "        u = normalize(xn)\n",
    "        v = normalize(yn)\n",
    "        sigma = np.linalg.norm(xn) * np.linalg.norm(yn)\n",
    "      W[:, i] = np.sqrt(S[i] * sigma) * u\n",
    "      H[i, :] = np.sqrt(S[i] * sigma) * v\n",
    "  return W, H\n",
    "W_nnsvd, H_nnsvd = nndsvd(tv_fit.toarray(), k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "35ec9d0d-cd6d-4ad2-b1a8-9dba7de6ec4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((737, 4), (4, 3272))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W_nnsvd.shape,H_nnsvd.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "1b8bcb25-6ba3-4ab7-8eeb-1a835f06539d",
   "metadata": {},
   "outputs": [],
   "source": [
    "W_nnsvd= np.maximum(W_nnsvd,1e-6)\n",
    "H_nnsvd= np.maximum(H_nnsvd,1e-6)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
